{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to process last 5 year FnO transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ledger': {'raw_dir': '../data/raw/', 'processed_dir': '../data/processed/'}, 'pnl': {'raw_dir': '../data/raw/', 'processed_dir': '../data/processed/'}, 'tradebook': {'raw_dir': '../data/raw/', 'processed_dir': '../data/processed/'}}\n",
      "raw_dir : ../data/raw/\n",
      "Printing df_pnl columns :  Index(['index', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
      "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13'],\n",
      "      dtype='object')\n",
      "Printing df_ledger columns :  Index(['particulars', 'posting_date', 'cost_center', 'voucher_type', 'debit',\n",
      "       'credit', 'net_balance'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gy/xs43v__d0mn25qy5kzxrnkrm0000gn/T/ipykernel_8899/2242009098.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_ledger = pd.read_csv(df_ledger_file_path, index_col=0, parse_dates=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load API Key and download directory from config file\n",
    "CONFIG_FILE = \"../config/file-config.json\"\n",
    "\n",
    "def load_config(config_path):\n",
    "    \"\"\"Load configuration from a JSON file.\"\"\"\n",
    "    with open(config_path, \"r\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Load config values\n",
    "config = load_config(CONFIG_FILE)\n",
    "print(config)\n",
    "# print(config)\n",
    "raw_dir = config[\"tradebook\"][\"raw_dir\"]\n",
    "processed_dir = config[\"tradebook\"][\"processed_dir\"]\n",
    "print(\"raw_dir :\", raw_dir)\n",
    "\n",
    "df_pnl_file_path = f'{raw_dir}/pnl-ZH5601-2020-2025.xlsx'\n",
    "df_ledger_file_path = f'{raw_dir}/ledger-ZH5601-2019-2025.csv'\n",
    "df_tradebook_file_path = f'{raw_dir}/tradebook-ZH5601-FO-2020.csv'\n",
    "\n",
    "df_pnl = pd.read_excel(df_pnl_file_path, index_col=0, parse_dates=True)\n",
    "df_pnl.reset_index(inplace=True)\n",
    "print(\"Printing df_pnl columns : \", df_pnl.columns)\n",
    "\n",
    "df_ledger = pd.read_csv(df_ledger_file_path, index_col=0, parse_dates=True)\n",
    "df_ledger.reset_index(inplace=True)\n",
    "print(\"Printing df_ledger columns : \", df_ledger.columns)\n",
    "\n",
    "# df_tradebook = pd.read_csv(df_tradebook_file_path, index_col=0, parse_dates=True)\n",
    "# df_tradebook.reset_index(inplace=True)\n",
    "# print(\"Printing df_tradebook columns : \", df_tradebook.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all files into consolidated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data file saved at :  ../data/processed/tradebook-consolidated-data-2020-2025.csv\n",
      "                  symbol  isin  trade_date exchange segment  series  \\\n",
      "0  HINDUNILVR20DEC2380CE   NaN  2020-12-14      NSE      FO     NaN   \n",
      "1  HINDUNILVR20DEC2380CE   NaN  2020-12-14      NSE      FO     NaN   \n",
      "2  HINDUNILVR20DEC2380CE   NaN  2020-12-14      NSE      FO     NaN   \n",
      "\n",
      "  trade_type  auction  quantity  price   trade_id          order_id  \\\n",
      "0        buy    False     300.0  50.00  500283425  1300000019296515   \n",
      "1       sell    False     300.0  45.15  500591592  1300000048651812   \n",
      "2        buy    False     300.0  46.30  500599413  1300000048788254   \n",
      "\n",
      "  order_execution_time expiry_date  \n",
      "0  2020-12-14T11:31:12  2020-12-31  \n",
      "1  2020-12-14T15:25:41  2020-12-31  \n",
      "2  2020-12-14T15:28:14  2020-12-31  \n"
     ]
    }
   ],
   "source": [
    "# Define the base file path and the list of file suffixes (23, 24, 28, 31, 53, 54, 55, 56= empty)\n",
    "base_file_path = f'{raw_dir}tradebook-ZH5601-FO-'\n",
    "file_suffixes = [2020, 2021, 2022, 2023, 2024, 2025]\n",
    "merged_df_total = pd.DataFrame()\n",
    "\n",
    "# Iterate over the file suffixes and merge the data\n",
    "for suffix in file_suffixes:\n",
    "    file_path = f'{base_file_path}{suffix}.csv'\n",
    "    # print(\"Processing file_path :\", file_path)\n",
    "    df_tradebook = pd.read_csv(file_path)\n",
    "    #, parse_dates=['trade_date'], index_col='trade_date')\n",
    "    # print(\"df_ned DataFrame shape :\", df_ned.shape[0])\n",
    "    # df_tradebook.reset_index(inplace=True)\n",
    "    # print(df_tradebook.columns)\n",
    "\n",
    "    if(merged_df_total.empty):\n",
    "        merged_df_total = df_tradebook.copy()\n",
    "    else:\n",
    "        # Only select columns that match the existing file\n",
    "        df_tradebook_subset = df_tradebook[merged_df_total.columns]\n",
    "        # Now concatenate with matching columns\n",
    "        merged_df_total = pd.concat([merged_df_total, df_tradebook_subset], axis=0, ignore_index=True)\n",
    "\n",
    "file_path = os.path.join(processed_dir, f\"tradebook-consolidated-data-2020-2025.csv\")  # Change extension as needed\n",
    "with open(file_path, \"wb\") as file:\n",
    "    merged_df_total.to_csv(file_path, index=False)\n",
    "    print(f\"Consolidated data file saved at : \", file_path)\n",
    "print(merged_df_total.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link instrument buy with instrument sell and calculate profile\n",
    "summarize instrument in understandable view\n",
    "link profile / loss with index move data\n",
    "perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter the DataFrame to include only the volume columns\n",
    "df_volume = merged_df_total[volume_columns]\n",
    "\n",
    "# Plot the volume columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "for col in df_volume.columns:\n",
    "    plt.plot(df_volume.index, df_volume[col], label=col)\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Volume')\n",
    "plt.title('Volume Variables Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(df_filtered['Total_Flow'], df_filtered['wind_speed_10m'], s=1, alpha=0.5)  # Adjust 's' for point size\n",
    "plt.xlabel('Total_Flow')\n",
    "plt.ylabel('Wind Speed')\n",
    "plt.title('Scatter Plot of Total_Flow vs Wind Speed')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(df_filtered['wind_speed_10m'], df_filtered['production_wind'], s=5, alpha=0.5)  # Adjust 's' for point size\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('Wind Energy Production')\n",
    "plt.title('Scatter Plot of Wind Speed vs Wind Energy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Drop rows with missing values in 'Price' or 'Load' columns\n",
    "df_filtered_ws = df_filtered[['production_wind', 'wind_speed_10m']].dropna()\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "r = np.corrcoef(df_filtered_ws['production_wind'], df_filtered_ws['wind_speed_10m'])\n",
    "print(\"Correlation coefficient matrix:\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Scatter plot for 'diffuse_radiation'\n",
    "axs[0].scatter(df_filtered['diffuse_radiation'], df_filtered['production_solar'], s=5, alpha=0.5)\n",
    "axs[0].set_xlabel('Diffuse Radiation')\n",
    "axs[0].set_ylabel('Solar Energy Production')\n",
    "axs[0].set_title('Scatter Plot of Diffuse Radiation vs Solar Energy Production')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Scatter plot for 'direct_normal_irradiance'\n",
    "axs[1].scatter(df_filtered['direct_normal_irradiance'], df_filtered['production_solar'], s=5, alpha=0.5)\n",
    "axs[1].set_xlabel('Direct Normal Irradiance')\n",
    "axs[1].set_ylabel('Solar Energy Production')\n",
    "axs[1].set_title('Scatter Plot of Direct Normal Irradiance vs Solar Energy Production')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Scatter plot for 'shortwave_radiation'\n",
    "axs[2].scatter(df_filtered['shortwave_radiation'], df_filtered['production_solar'], s=5, alpha=0.5)\n",
    "axs[2].set_xlabel('Shortwave Radiation')\n",
    "axs[2].set_ylabel('Solar Energy Production')\n",
    "axs[2].set_title('Scatter Plot of Shortwave Radiation vs Solar Energy Production')\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Select the desired columns\n",
    "selected_columns = [\n",
    "    'Load', 'Price', 'Total_Flow', 'temperature_2m', 'apparent_temperature', \n",
    "    'cloud_cover', 'wind_speed_10m', 'diffuse_radiation', 'direct_normal_irradiance', \n",
    "    'shortwave_radiation', 'wind_speed_100m', 'location', 'production_wind', \n",
    "    'production_solar', \n",
    "    'production_heatpump', \n",
    "    'production_cofiring', \n",
    "    'production_geothermal', \n",
    "    'production_other', \n",
    "    'production_waste', \n",
    "    'production_biooil', \n",
    "    'production_biomass', \n",
    "    'production_wood', \n",
    "    'production_windoffshore', \n",
    "    'production_fossilgaspower', \n",
    "    'production_fossilhardcoal', \n",
    "    'production_nuclear', \n",
    "    'production_wastepower', \n",
    "    'production_windoffshoreB', \n",
    "    'production_biomasspower', \n",
    "    'production_otherpower', \n",
    "    'production_electricitymix', \n",
    "    'production_CHP_total', \n",
    "    'production_solarthermal', \n",
    "    'production_allconsuminggas'\n",
    "]\n",
    "\n",
    "# Filter the DataFrame to include only the selected columns\n",
    "df_selected = df_filtered[selected_columns]\n",
    "\n",
    "# Select only the numerical columns\n",
    "df_numeric = df_selected.select_dtypes(include=['number'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df_numeric.corr()\n",
    "\n",
    "# Create an interactive heatmap with Plotly\n",
    "fig = px.imshow(corr_matrix, \n",
    "                labels=dict(color=\"Correlation\"), \n",
    "                x=corr_matrix.columns, \n",
    "                y=corr_matrix.columns,\n",
    "                color_continuous_scale='RdBu_r',\n",
    "                zmin=-1, zmax=1)\n",
    "\n",
    "fig.update_layout(title='Correlation Matrix', width=800, height=800)\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(\"correlation_matrix.html\")\n",
    "\n",
    "# Display a message to the user\n",
    "print(\"The interactive correlation matrix has been saved as 'correlation_matrix.html'. Open this file in your browser to view it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color map for the variables\n",
    "colors = plt.cm.get_cmap('tab10', 5)  # Use a colormap with 5 distinct colors\n",
    "\n",
    "# Plot the scatter plot with different colors for each variable\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(df_filtered['Flow_DE'], df_filtered['wind_speed_10m'], s=1, alpha=0.5, color=colors(0), label='Flow_DE')\n",
    "plt.scatter(df_filtered['Flow_DK'], df_filtered['wind_speed_10m'], s=1, alpha=0.5, color=colors(1), label='Flow_DK')\n",
    "plt.scatter(df_filtered['Flow_BE'], df_filtered['wind_speed_10m'], s=1, alpha=0.5, color=colors(2), label='Flow_BE')\n",
    "plt.scatter(df_filtered['Flow_GB'], df_filtered['wind_speed_10m'], s=1, alpha=0.5, color=colors(3), label='Flow_GB')\n",
    "plt.scatter(df_filtered['Flow_NO'], df_filtered['wind_speed_10m'], s=1, alpha=0.5, color=colors(4), label='Flow_NO')\n",
    "\n",
    "plt.xlabel('Flow')\n",
    "plt.ylabel('Wind Speed')\n",
    "plt.title('Scatter Plot of Flow vs Wind Speed')\n",
    "plt.legend(title='Variable')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_totalflow = df_filtered['Total_Flow'].isna().sum()\n",
    "print(nan_totalflow)\n",
    "nan_temp = df_filtered['temperature_2m'].isna().sum()\n",
    "print(nan_temp)\n",
    "nan_cloud = df_filtered['cloud_cover'].isna().sum()\n",
    "print(nan_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Drop rows with missing values in the relevant columns\n",
    "df_filtered_regr = df_filtered[['Price', 'Load', 'Total_Flow', 'temperature_2m', 'apparent_temperature', 'cloud_cover', 'wind_speed_10m', 'diffuse_radiation', \n",
    "    'direct_normal_irradiance', 'shortwave_radiation', 'wind_speed_100m', 'production_all', 'production_wind', 'production_solar', 'production_heatpump', \n",
    "    'production_cofiring', 'production_geothermal', 'production_other', 'production_waste', 'production_biooil', 'production_biomass', 'production_wood', \n",
    "    'production_windoffshore', 'production_fossilgaspower', 'production_fossilhardcoal', 'production_nuclear', 'production_wastepower', 'production_windoffshoreB', \n",
    "    'production_biomasspower', 'production_otherpower', 'production_electricitymix', 'production_CHP_total', 'production_solarthermal', \n",
    "    'production_allconsuminggas']].dropna()\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if df_filtered_regr.empty:\n",
    "    print(\"The DataFrame is empty after dropping rows with missing values.\")\n",
    "else:\n",
    "    # Define the features (X) and the target (y)\n",
    "    X = df_filtered_regr[['Load', 'Total_Flow', 'temperature_2m', 'apparent_temperature', 'cloud_cover', 'wind_speed_10m', 'diffuse_radiation', 'direct_normal_irradiance', \n",
    "    'shortwave_radiation', 'wind_speed_100m', 'production_all', 'production_wind', 'production_solar', 'production_heatpump', 'production_cofiring', 'production_geothermal', \n",
    "    'production_other', 'production_waste', 'production_biooil', 'production_biomass', 'production_wood', 'production_windoffshore', 'production_fossilgaspower', \n",
    "    'production_fossilhardcoal', 'production_nuclear', 'production_wastepower', 'production_windoffshoreB', 'production_biomasspower', 'production_otherpower', \n",
    "    'production_electricitymix', 'production_CHP_total', 'production_solarthermal', 'production_allconsuminggas']]\n",
    "    y = df_filtered_regr['Price']\n",
    "\n",
    "    # Train the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Make predictions on the same dataset\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "    # Get the coefficients of the model\n",
    "    coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "    print(coefficients)\n",
    "\n",
    "        # Sort the coefficients by absolute value\n",
    "    coefficients['abs_coefficient'] = coefficients['Coefficient'].abs()\n",
    "    coefficients = coefficients.sort_values(by='abs_coefficient', ascending=True)\n",
    "\n",
    "    # Plot the coefficients\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(coefficients.index, coefficients['Coefficient'], color='skyblue')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature Importance in Predicting Price')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_regr.head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fno-trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
